# -*- coding: utf-8 -*-
"""The Starving Software Tester.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O2t0JsEQ7qBD4XV4AF2-UNjm0ojfbm6c
"""

# Install the necessary dependencies
!pip install selenium
!apt update
!apt install chromium-chromedriver

# Import necessary packages
from selenium import webdriver
from selenium.webdriver.common.by import By
import pandas as pd

# Configure Chromedriver options
options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

# Configure variables
_driver = webdriver.Chrome(options=options)
_url = "https://testdevjobs.com/location/remote-united-kingdom"

### Modified from@ https://colab.research.google.com/drive/14kXYQCSGVye4bBKKExtuHOeq32bc4xbW?usp=sharing#scrollTo=dRAMB1_yt1jJ

# Get job listings
def getJobListings(driver: str, url: str):
  driver.get(url)
  job_listings = _driver.find_elements(By.XPATH, "//*[@class='job-deatils']")
  return job_listings

def fetchJobDetailsAndAddToList(driver: str, selector: str, empty_list):
  job_detail = driver.find_element(By.XPATH, selector).text
  empty_list.append(job_detail)

def traverseJobs(driver: str, url: str):
  job_listings = getJobListings(driver, url)
  job_count = 0
  job_title = []

  job_location = []
  job_skills = []
  job_id = []

  for job in job_listings:
    fetchJobDetailsAndAddToList(driver, "//*[@class='ml-5 jobtitle is-size-5 has-text-weight-semibold']", job_title) # add title to jobs' titles list
    fetchJobDetailsAndAddToList(driver, "//*[@class='tags ml-5 mr-1 mb-0']", job_location) # add location to jobs' locations list
    fetchJobDetailsAndAddToList(driver, "//*[@class='tags ml-5 mr-1']", job_skills)
    job_count =+ 1
    job_id.append(job_count)

  jobs_panda_frame = pd.DataFrame(list(zip(job_id, job_title, job_location, job_skills)), columns = ['ID', 'Title', 'Location', 'Skills'])

  return jobs_panda_frame.to_csv('jobs.csv')

traverseJobs(_driver, _url)

# Prepare data for Voyant processing

jobs_data = pd.read_csv("/content/jobs.csv")
jobs_data.head()
skills_csv = jobs_data['Skills'].to_csv('skills.csv')